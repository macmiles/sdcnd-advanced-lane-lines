{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Line Finder\n",
    "The goals of this project are as follows:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import project dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import project dependencies\n",
    "import cv2, time, random, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define camera calibration and undistortion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_calibration(image_paths,plot=False):\n",
    "    images_n = len(image_paths)\n",
    "    \n",
    "    # define object points for corners\n",
    "    chess_row_corners = 6\n",
    "    chess_col_corners = 9\n",
    "    objp = np.zeros((chess_row_corners*chess_col_corners,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:chess_col_corners, 0:chess_row_corners].T.reshape(-1,2)\n",
    "\n",
    "    # load images using matplotlibs image.imread() function, find & draw chessboard corner points, and display images\n",
    "    chess_images, obj_pts, img_pts = [],[],[]\n",
    "    if plot:\n",
    "        print('Number of calibration images:',images_n)\n",
    "        fig = plt.figure(figsize=(15,90))\n",
    "        fig.subplots_adjust(wspace=0.1,hspace=0.1)\n",
    "    corner_count = 0\n",
    "    for image_path in image_paths:\n",
    "        img = mpimg.imread(image_path) # reads image in as an RGB\n",
    "        img_copy = np.copy(img)\n",
    "        chess_images.append(img) # saves image to a list\n",
    "        img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) # converts image to grayscale\n",
    "        ret, corners = cv2.findChessboardCorners(img_gray,(chess_col_corners,chess_row_corners),None)\n",
    "        if ret:\n",
    "            corner_count += 2\n",
    "            obj_pts.append(objp)\n",
    "            img_pts.append(corners)\n",
    "            img_corners = cv2.drawChessboardCorners(img_copy,(chess_col_corners,chess_row_corners),corners,ret)\n",
    "            if plot:\n",
    "                ax1 = fig.add_subplot(images_n,2,corner_count-1)\n",
    "                ax1.imshow(img)\n",
    "                ax1.axis('off')\n",
    "                ax1.set_title('Original')\n",
    "                ax2 = fig.add_subplot(images_n,2,corner_count)\n",
    "                ax2.imshow(img_corners)\n",
    "                ax2.axis('off')\n",
    "                ax2.set_title('Corners Found')\n",
    "    \n",
    "    image_shape = (chess_images[0].shape[1],chess_images[0].shape[0])\n",
    "    if plot:\n",
    "        print('Chessboard corners found: {} out of {}'.format(int(corner_count/2),images_n))\n",
    "        print('Calibration complete.')\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_pts, img_pts, image_shape, None, None)\n",
    "    return chess_images, ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "def undistort_image(img):\n",
    "    return cv2.undistort(img,mtx,dist,None,mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating camera\n",
    "We use a variety of chessboard images to properly calibrate the camera first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import all chessboard camera calibration images using the glob package\n",
    "chess_image_paths = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# retrieve camera calibration values using our custom camera_calibration function\n",
    "chess_images, ret, mtx, dist, rvecs, tvecs = camera_calibration(chess_image_paths,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistorting images\n",
    "Then using the camera matrix we calculated in the calibration phase, we're able to undistort images that were previously distorted as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_img_chess = chess_images[11] # load test image\n",
    "test_img_chess_undistorted = undistort_image(test_img_chess) # undistort test image\n",
    "\n",
    "f,(ax1,ax2) = plt.subplots(1,2,figsize=(20,30))\n",
    "ax1.imshow(test_img_chess)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Original')\n",
    "ax2.imshow(test_img_chess_undistorted)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Undistorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_road = mpimg.imread('./test_images/test3.jpg') # load test image\n",
    "test_img_road_undistorted = undistort_image(test_img_road) # undistort test image\n",
    "\n",
    "f,(ax1,ax2) = plt.subplots(1,2,figsize=(20,30))\n",
    "ax1.imshow(test_img_road)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Original')\n",
    "ax2.imshow(test_img_road_undistorted)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Undistorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold function that returns an image filtered on gradient and color parameters\n",
    "We apply an RGB to HLS conversion to our image as this simplifies the color space. This allows us to define upper and lower regions in our image that filter the white/yellow lane lines. \n",
    "\n",
    "In addition, we utilize sobel operators to measure the rate of change in the image. This is proves to be quite useful when mapping out the edges in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_threshold_pipeline(img,sobel_kernel=3,blur_kernel=5,color_thresh=(0,255),mag_thresh=(0,255),dir_thresh=(0,np.pi/2)):\n",
    "    # avoid writing over original image\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # apply image blur\n",
    "    # img = cv2.GaussianBlur(img,(blur_kernel,blur_kernel),0)\n",
    "    \n",
    "    # convert color space\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS) # converts image to HLS (hue, light, saturation) color space\n",
    "    \n",
    "    # white color upper and lower bounds -- we only want to bound the light channel in HLS for white\n",
    "    white_lower_limit = np.array([0,210,0],dtype=np.uint8)\n",
    "    white_upper_limit = np.array([255,255,255],dtype=np.uint8)\n",
    "    binary_out_white = cv2.inRange(img,white_lower_limit,white_upper_limit)\n",
    "    \n",
    "    # yellow color upper and lower bounds -- we only want to bound the hue channel in HLS for yellow\n",
    "    yellow_lower_limit = np.array([15,0,110],dtype=np.uint8)\n",
    "    yellow_upper_limit = np.array([40,220,255],dtype=np.uint8)\n",
    "    binary_out_yellow = cv2.inRange(img,yellow_lower_limit,yellow_upper_limit)\n",
    "    \n",
    "    img_s = img[:,:,2] # saves only the saturation channel\n",
    "    binary_out_s = np.zeros_like(img_s)\n",
    "    binary_out_s[(img_s >= 165) & (img_s <= 255)] = 1\n",
    "    \n",
    "    # calculating sobel (gradient) across x & y plane\n",
    "    sobelx = cv2.Sobel(img_s,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_s,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    sobelx_abs = np.absolute(sobelx)\n",
    "    sobely_abs = np.absolute(sobely)\n",
    "    \n",
    "    sobelx_scaled = np.uint8(255*sobelx_abs/np.max(sobelx_abs))\n",
    "    sobely_scaled = np.uint8(255*sobely_abs/np.max(sobely_abs))\n",
    "\n",
    "    binary_out_x = np.zeros_like(sobelx_scaled)\n",
    "    binary_out_y = np.zeros_like(sobely_scaled)\n",
    "    \n",
    "    binary_out_x[(sobelx_scaled >= color_thresh[0]) & (sobelx_scaled <= color_thresh[1])] = 1\n",
    "    binary_out_y[(sobely_scaled >= color_thresh[0]) & (sobely_scaled <= color_thresh[1])] = 1\n",
    "    \n",
    "    # calculating gradient magnitude\n",
    "    gradient_magnitude = np.sqrt(sobelx**2+sobely**2)\n",
    "    gradient_magnitude_scaled = np.uint8(255*gradient_magnitude/np.max(gradient_magnitude))\n",
    "    \n",
    "    binary_out_magnitude = np.zeros_like(gradient_magnitude_scaled)\n",
    "    binary_out_magnitude[(gradient_magnitude_scaled >= mag_thresh[0]) & (gradient_magnitude_scaled <= mag_thresh[1])] = 1\n",
    "\n",
    "    # calculating gradient direction\n",
    "    gradient_direction = np.arctan2(sobely_abs,sobelx_abs)\n",
    "\n",
    "    binary_out_direction = np.zeros_like(gradient_direction)\n",
    "    binary_out_direction[(gradient_direction >= dir_thresh[0]) & (gradient_direction <= dir_thresh[1])] = 1\n",
    "    \n",
    "    return binary_out_white,binary_out_yellow,binary_out_s,binary_out_x,binary_out_y,binary_out_magnitude,binary_out_direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple thresholds to build a more reliable image\n",
    "We utilize a combination of color and gradient thresholds to develop a finalized image that accurately picks up lane line information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_white,binary_yellow,binary_s,binary_x,binary_y,binary_mag,binary_dir=gradient_threshold_pipeline(test_img_road_undistorted,sobel_kernel=11,color_thresh=(15,50),mag_thresh=(25,255),dir_thresh=(0.65,1.25))\n",
    "binary_combined1 = np.zeros_like(binary_x)\n",
    "binary_combined1[((binary_x == 1) & (binary_y == 1)) | ((binary_mag == 1) & (binary_dir == 1))] = 1\n",
    "binary_combined2 = np.zeros_like(binary_x)\n",
    "binary_combined2[((binary_white == 255) & (binary_combined1 == 1)) | ((binary_yellow == 255) & (binary_combined1 == 1))] = 1\n",
    "final_image = np.dstack((binary_yellow,binary_white,binary_combined2*255))\n",
    "\n",
    "binary_list = [test_img_road,test_img_road_undistorted,binary_white,binary_yellow,binary_s,binary_x,binary_y,binary_mag,binary_dir,binary_combined1,binary_combined2,final_image]\n",
    "binary_list_labels = ['test_img_road','test_img_road_undistorted','binary_white','binary_yellow','binary_s','binary_x','binary_y','binary_mag','binary_dir','binary_combined1','binary_combined2','final_image']\n",
    "binary_n = len(binary_list)\n",
    "\n",
    "f,ax = plt.subplots(int(binary_n/2),2,figsize=(20,40))\n",
    "i = -1\n",
    "for ax_i in ax:\n",
    "#     ax[i] = fig.subplots(binary_n,1,i+1)\n",
    "    for j in range(len(ax_i)):\n",
    "        i += 1\n",
    "        try: \n",
    "            binary_list[i].shape[2]\n",
    "            ax_i[j].imshow(binary_list[i])\n",
    "            ax_i[j].axis('off')\n",
    "            ax_i[j].set_title(binary_list_labels[i])\n",
    "        except:\n",
    "            try:\n",
    "                ax_i[j].imshow(binary_list[i],cmap='gray')\n",
    "                ax_i[j].axis('off')\n",
    "                ax_i[j].set_title(binary_list_labels[i])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image_gray = cv2.cvtColor(final_image,cv2.COLOR_RGB2GRAY)\n",
    "final_image_binary = np.zeros_like(final_image_gray)\n",
    "final_image_binary[final_image_gray > 0] = 1\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(final_image_binary,cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot source points on the image\n",
    "In order to apply a birds-eye view perspective transform to an image, lets first plot our source points on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = final_image_binary.shape[0]\n",
    "width = final_image_binary.shape[1]\n",
    "width_offset_top = 0.44\n",
    "width_offset_bottom = 0.08\n",
    "height_offset = 0.6\n",
    "x1,y1 = width*width_offset_bottom,height\n",
    "x2,y2 = width*width_offset_top,height*height_offset\n",
    "x3,y3 = width*(1-width_offset_top),height*height_offset\n",
    "x4,y4 = width*(1-width_offset_bottom),height\n",
    "x = [x1,x2,x3,x4]\n",
    "y = [y1,y2,y3,y4]\n",
    "labels = ['x1,y1','x2,y2','x3,y3','x4,y4']\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ax.imshow(final_image_binary,cmap='gray')\n",
    "# ax.axis('off')\n",
    "ax.plot(x,y,'o-',color='red')\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax.annotate(label,(x[i],y[i]),color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply birds-eye view perspective transform\n",
    "Applying an accurate perspective transform to our binary image is essential to determining lane curvature later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_mask(img, region):\n",
    "    crop = np.zeros_like(img)\n",
    "    crop_value = 255\n",
    "    cv2.fillPoly(crop, region, crop_value) # sets entire cropped region to 255\n",
    "    img_crop = cv2.bitwise_and(img, crop) # returns cropped img where crop values are non-zero\n",
    "    return img_crop\n",
    "\n",
    "def perspective_transform(img):\n",
    "    # retrieve image dimensions\n",
    "    height = final_image_binary.shape[0]\n",
    "    width = final_image_binary.shape[1]\n",
    "    \n",
    "    # define source points\n",
    "    width_offset_top = 0.44\n",
    "    width_offset_bottom = 0.08\n",
    "    height_offset = 0.6\n",
    "    \n",
    "    x1,y1 = width*width_offset_bottom,height\n",
    "    x2,y2 = width*width_offset_top,height*height_offset\n",
    "    x3,y3 = width*(1-width_offset_top),height*height_offset\n",
    "    x4,y4 = width*(1-width_offset_bottom),height\n",
    "    \n",
    "    # set source points\n",
    "    src = np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])\n",
    "    \n",
    "    # define destination points\n",
    "    width_offset_top = 0.3\n",
    "    width_offset_bottom = 0.4\n",
    "    height_offset = -1\n",
    "\n",
    "    x1,y1 = width*width_offset_bottom,height\n",
    "    x2,y2 = width*width_offset_top,height*height_offset\n",
    "    x3,y3 = width*(1-width_offset_top),height*height_offset\n",
    "    x4,y4 = width*(1-width_offset_bottom),height\n",
    "    \n",
    "    dst = np.float32([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Use cv2.warpPerspective() to warp image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    unwarped = cv2.warpPerspective(warped, M_inv, (warped.shape[1],warped.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped,unwarped,M,M_inv\n",
    "\n",
    "final_image_warped,final_image_unwarped,M,M_inv = perspective_transform(final_image_binary)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(final_image_warped,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask region of interest\n",
    "This step masks out the noise around the lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mask points\n",
    "width_offset_top = 0.36\n",
    "width_offset_bottom = 0.36\n",
    "height_offset = 0\n",
    "\n",
    "x1,y1 = width*width_offset_bottom,height\n",
    "x2,y2 = width*width_offset_top,height*height_offset\n",
    "x3,y3 = width*(1-width_offset_top),height*height_offset\n",
    "x4,y4 = width*(1-width_offset_bottom),height\n",
    "\n",
    "region = np.array([[(x1,y1),(x2,y2),(x3,y3),(x4,y4)]],dtype=np.int32)\n",
    "final_image_warped_masked = region_mask(final_image_warped,region)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(final_image_warped_masked,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial lane line detection\n",
    "We split the warped image into 6 parts (windows), then we use a histogram in the first window to determine the general location of the left/right lane lines. The location is determined based on where the histogram peaks are across the 1280x720 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def initial_lane_detection(img,plot=False):\n",
    "    # find the general region of where lanes are located on image\n",
    "    height,width = img.shape[:2]\n",
    "    hist = np.sum(final_image_warped_masked[-height//6:,:],axis=0)\n",
    "    hist_midpoint = np.int(hist.shape[0]//2)\n",
    "    initial_left_lane_x = np.argmax(hist[:hist_midpoint])\n",
    "    initial_right_lane_x = np.argmax(hist[hist_midpoint:]) + hist_midpoint\n",
    "    if plot:\n",
    "        print('Initial left lane max: {}, Initial right lane max: {}'.format(initial_left_lane_x,initial_right_lane_x))\n",
    "        fig,ax = plt.subplots(figsize=(20,10))\n",
    "        ax.plot(hist)\n",
    "        ax.set_title('Avg Lane Lines Detected')\n",
    "        x = [initial_left_lane_x,initial_right_lane_x]\n",
    "        y = [0,0]\n",
    "        labels = ['left lane max','right lane max']\n",
    "        ax.plot(x,y,'o',color='r')\n",
    "        for i,label in enumerate(labels):\n",
    "            ax.annotate(label,(x[i],y[i]))\n",
    "    return initial_left_lane_x, initial_right_lane_x\n",
    "    \n",
    "initial_left_lane_x, initial_right_lane_x = initial_lane_detection(final_image_warped_masked,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous lane line detection\n",
    "Now that we know the general region of where the lanes are located, we can use this information to scan the location of the new lanes at the upcoming windows.\n",
    "\n",
    "Using the collected (and imputed) lane line locations, we fit a line and retrieve the best fit second order polynomial values. Second order polynomial function:\n",
    "![Second Order Polynomial](./media/formula_second_order_poly.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def continuous_lane_detection(img_warped_masked,initial_left_lane_x, initial_right_lane_x,plot=False):\n",
    "    img = np.copy(img_warped_masked)\n",
    "    # define lane finding parameters\n",
    "    margin = 40\n",
    "    empty_window_augmentation = True # when an empty window is found, aggregate lane line locations using historical data\n",
    "    historical_n = 5 # number of windows we want to look back in time when calculating imputed lane locations\n",
    "    window_n = 10 # number of windows we want to split the warped image\n",
    "\n",
    "    # build final image\n",
    "    img_out = np.dstack([img,img,img])*255\n",
    "\n",
    "    # define window parameters\n",
    "    height,width = img_out.shape[:2]\n",
    "    window_height = height//window_n\n",
    "    window_y_start = height-window_height\n",
    "    window_y_end = height\n",
    "    window_left_x_start = initial_left_lane_x - margin\n",
    "    window_left_x_end = initial_left_lane_x + margin\n",
    "    window_right_x_start = initial_right_lane_x - margin\n",
    "    window_right_x_end = initial_right_lane_x + margin\n",
    "    left_lane_x_list,right_lane_x_list,y_x_list = [],[],[]\n",
    "    left_lane_y_list,right_lane_y_list = [],[]\n",
    "    \n",
    "    # initialize lane locations\n",
    "    left_lane_x = initial_left_lane_x\n",
    "    right_lane_x = initial_right_lane_x\n",
    "\n",
    "    if plot:\n",
    "        fig,ax = plt.subplots(window_n,1,figsize=(20,20))\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    for i in reversed(range(window_n)):\n",
    "        # print('i: {}, window_y_start: {}, window_y_end: {}, window_left_x_start: {}, window_left_x_end: {}, window_right_x_start: {}, window_right_x_end: {}'.format(i,window_y_start,window_y_end,window_left_x_start,window_left_x_end,window_right_x_start,window_right_x_end))\n",
    "        hist = np.sum(img[window_y_start:window_y_end,:],axis=0)\n",
    "        if np.argmax(hist[np.max([window_left_x_start,0]):np.min([window_left_x_end,width])]) > 0:\n",
    "            left_lane_x = np.argmax(hist[np.max([window_left_x_start,0]):np.min([window_left_x_end,width])]) + np.max([window_left_x_start,0])\n",
    "            left_lane_x_list.append(left_lane_x)\n",
    "            left_lane_y_list.append((window_y_end+window_y_start)/2)\n",
    "        else:\n",
    "            # if no points are found in argmax, we impute the lane locations using recent data\n",
    "            lane_range_list = list(reversed(range(1,historical_n+1)))\n",
    "            for lane_range in lane_range_list:\n",
    "                # retrieve most recent lane avg points for left lane and compute average\n",
    "                if len(left_lane_x_list) == 0:\n",
    "                    left_lane_x = initial_left_lane_x\n",
    "                    left_lane_y = (window_y_end+window_y_start)/2\n",
    "                    left_lane_x_list.append(left_lane_x)\n",
    "                    left_lane_y_list.append(left_lane_y)\n",
    "                    break\n",
    "                elif len(left_lane_x_list) >= lane_range:\n",
    "                    recent_delta = int(sum([(left_lane_x_list[-i]-left_lane_x_list[-(i+1)]) for i in range(1,lane_range,2)])/lane_range)\n",
    "                    left_lane_x += recent_delta\n",
    "                    break\n",
    "\n",
    "        if np.argmax(hist[np.max([window_right_x_start,0]):np.min([window_right_x_end,width])]) > 0:\n",
    "            right_lane_x = np.argmax(hist[np.max([window_right_x_start,0]):np.min([window_right_x_end,width])]) + np.max([window_right_x_start,0])\n",
    "            right_lane_x_list.append(right_lane_x)\n",
    "            right_lane_y_list.append((window_y_end+window_y_start)/2)\n",
    "        else:\n",
    "            # if no points are found in argmax, we impute the lane locations using recent data\n",
    "            lane_range_list = list(reversed(range(1,historical_n+1)))\n",
    "            for lane_range in lane_range_list:\n",
    "                # retrieve most recent lane avg points for right lane and compute average\n",
    "                if len(right_lane_x_list) == 0:\n",
    "                    right_lane_x = initial_right_lane_x\n",
    "                    right_lane_y = (window_y_end+window_y_start)/2\n",
    "                    right_lane_x_list.append(right_lane_x)\n",
    "                    right_lane_y_list.append(right_lane_y)\n",
    "                    break\n",
    "                elif len(right_lane_x_list) >= lane_range:\n",
    "                    recent_delta = int(sum([(right_lane_x_list[-i]-right_lane_x_list[-(i+1)]) for i in range(1,lane_range,2)])/lane_range)\n",
    "                    right_lane_x += recent_delta\n",
    "\n",
    "        y_x_list.append((window_y_end+window_y_start)/2)\n",
    "\n",
    "        if plot:\n",
    "            ax[i].plot(hist)\n",
    "            ax[i].set_title('window y region: ['+str(window_y_start)+','+str(window_y_end)+']')\n",
    "            x = [left_lane_x,right_lane_x]\n",
    "            y = [0,0]\n",
    "            labels = ['left lane avg','right lane avg']\n",
    "            ax[i].plot(x,y,'o',color='r')\n",
    "            for j,label in enumerate(labels):\n",
    "                ax[i].annotate(label,(x[j],y[j]))\n",
    "\n",
    "        # draw window scan region\n",
    "        cv2.rectangle(img_out,(window_left_x_start,window_y_start),(window_left_x_end,window_y_end),[0,255,0],2)\n",
    "        cv2.rectangle(img_out,(window_right_x_start,window_y_start),(window_right_x_end,window_y_end),[0,255,0],2)\n",
    "\n",
    "        # update next window scan region\n",
    "        window_left_x_start = left_lane_x - margin\n",
    "        window_left_x_end = left_lane_x + margin\n",
    "        window_right_x_start = right_lane_x - margin\n",
    "        window_right_x_end = right_lane_x + margin\n",
    "        window_y_start -= window_height\n",
    "        window_y_end -= window_height\n",
    "\n",
    "    y_plot = np.linspace(0,height-1,height)\n",
    "    left_lane_fit = np.polyfit(left_lane_y_list,left_lane_x_list,2) # finds best fit\n",
    "    left_lane_fit_x = left_lane_fit[0]*y_plot**2 + left_lane_fit[1]*y_plot + left_lane_fit[2] # determines x values in respect to the y_plot\n",
    "    right_lane_fit = np.polyfit(right_lane_y_list,right_lane_x_list,2) # finds best fit\n",
    "    right_lane_fit_x = right_lane_fit[0]*y_plot**2 + right_lane_fit[1]*y_plot + right_lane_fit[2] # determines x values in respect to the y_plot\n",
    "    if plot:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(img_out)\n",
    "        plt.plot(left_lane_x_list,left_lane_y_list,'o',color='r')\n",
    "        plt.plot(right_lane_x_list,right_lane_y_list,'o',color='r')\n",
    "        plt.plot(left_lane_fit_x,y_plot,'-',color='yellow')\n",
    "        plt.plot(right_lane_fit_x,y_plot,'-',color='yellow')\n",
    "    \n",
    "    return img_out,left_lane_fit,right_lane_fit,left_lane_fit_x,right_lane_fit_x,left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list,y_plot\n",
    "\n",
    "img_out,left_lane_fit,right_lane_fit,left_lane_fit_x,right_lane_fit_x,left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list,y_plot = continuous_lane_detection(final_image_warped_masked,initial_left_lane_x,initial_right_lane_x,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating radius of curvature\n",
    "1. In order to calculate the radius of curvature, we first need to find the 1st and 2nd derivatives of our second order polynomial function:\n",
    "![second_order_poly](./media/formula_second_order_poly.png)\n",
    "![derivatives](./media/formula_12derivatives.png)\n",
    "\n",
    "2. We convert our pixel scale into real world coordinates using an appropriate meter to pixel ratio:\n",
    "![Pixel Conversion](./media/formula_pixel_conversion.png)\n",
    "\n",
    "3. After calculating their respective derivatives, we estimate the radius of curvature for both left/right lane lines using our curvature formula:\n",
    "![R-Curve1](./media/formula_rcurve1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvature(left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list):\n",
    "#     img_out = np.copy(img)\n",
    "    mpp_y = 27/720 # meters per pixel y\n",
    "    mpp_x = 3.7/500 # meters per pixel x\n",
    "    y_value = np.max(y_plot)\n",
    "#     quadratic_coeff = 3e-4\n",
    "#     leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) for y in ploty])\n",
    "#     rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) for y in ploty])\n",
    "    \n",
    "    left_lane_y = np.array(left_lane_y_list)\n",
    "    left_lane_x = np.array(left_lane_x_list)\n",
    "    left_lane_fit = np.polyfit(left_lane_y*mpp_y,left_lane_x*mpp_x,2) # finds best fit\n",
    "\n",
    "    right_lane_y = np.array(right_lane_y_list)\n",
    "    right_lane_x = np.array(right_lane_x_list)\n",
    "    right_lane_fit = np.polyfit(right_lane_y*mpp_y,right_lane_x*mpp_x,2) # finds best fit\n",
    "    r_curve_left = ((1+(2*left_lane_fit[0]*y_plot*mpp_y+left_lane_fit[1])**2)**1.5)/np.absolute(2*left_lane_fit[0])\n",
    "    r_curve_right = ((1+(2*right_lane_fit[0]*y_plot*mpp_y+right_lane_fit[1])**2)**1.5)/np.absolute(2*right_lane_fit[0])\n",
    "    \n",
    "    r_curve_left_value = np.average(r_curve_left) # curve average\n",
    "    r_curve_right_value = np.average(r_curve_right) # curve average\n",
    "    return r_curve_left_value,r_curve_right_value,left_lane_fit,right_lane_fit\n",
    "\n",
    "r_curve_left,r_curve_right,left_lane_fit,right_lane_fit = curvature(left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list)\n",
    "r_curve_left,r_curve_right,left_lane_fit,right_lane_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot lane mask and text info to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_lane_mask(img_undistorted,img_warp,r_curve_left,r_curve_right,left_lane_fit_x,right_lane_fit_x,left_lane_fit,right_lane_fit,y_plot):\n",
    "#     mpp_x = 1/1280 # meters per pixel x\n",
    "    y_value = np.max(y_plot) # center offset is evaluated at this y location (towards the bottom of image)\n",
    "    \n",
    "    img_undistorted_out = np.copy(img_undistorted)\n",
    "    img_warp_out = np.copy(img_warp)\n",
    "    zero_binary = np.zeros_like(img_warp_out).astype(np.uint8)\n",
    "    zero_rgb = np.dstack((zero_binary,zero_binary,zero_binary))\n",
    "\n",
    "    left_lane_pts = np.array([np.transpose(np.vstack([left_lane_fit_x,y_plot]))])\n",
    "    right_lane_pts = np.array([np.flipud(np.transpose(np.vstack([right_lane_fit_x,y_plot])))])\n",
    "    lane_pts = np.hstack((left_lane_pts,right_lane_pts))\n",
    "\n",
    "    # plot mask\n",
    "    image_shape = (img_undistorted_out.shape[1],img_undistorted_out.shape[0])\n",
    "    cv2.fillPoly(zero_rgb,np.int_([lane_pts]), (0,255,0))\n",
    "    lane_overlay = cv2.warpPerspective(zero_rgb,M_inv,image_shape)\n",
    "\n",
    "    height,width = img_undistorted_out.shape[:2]\n",
    "    mid_x = width//2\n",
    "    \n",
    "    left_lane_x = left_lane_fit[0]*y_value**2 + left_lane_fit[1]*y_value + left_lane_fit[2]\n",
    "    right_lane_x = right_lane_fit[0]*y_value**2 + right_lane_fit[1]*y_value + right_lane_fit[2]\n",
    "    \n",
    "#     center_position = ((left_lane_pts[0,0,0]+right_lane_pts[0,0,0])/2 - mid_x) * mpp_x\n",
    "    center_position = ((left_lane_x + right_lane_x)/2 - mid_x)/width/2\n",
    "    if center_position > 0:\n",
    "        direction = 'right'\n",
    "    else:\n",
    "        direction = 'left'\n",
    "\n",
    "    r_curve_avg = (r_curve_left + r_curve_right)/2\n",
    "    final_out = cv2.addWeighted(img_undistorted,1,lane_overlay,0.22,0)\n",
    "    if r_curve_avg < 15000:\n",
    "        cv2.putText(final_out,'Lane Curvature Radius: {:.0f}m'.format(r_curve_avg),(20,40),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "    else:\n",
    "        cv2.putText(final_out,'Lane Curvature Radius: inf',(20,40),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "#     cv2.putText(final_out,'Left Lane Curvature Radius: {:.2f}m'.format(r_curve_left),(20,40),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "#     cv2.putText(final_out,'Right Lane Curvature Radius: {:.2f}m'.format(r_curve_right),(20,80),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "    cv2.putText(final_out,'Center Offset: {:.3f}m {}'.format(np.abs(center_position),direction),(20,80),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "    return final_out\n",
    "\n",
    "final_out = plot_lane_mask(test_img_road_undistorted,final_image_warped_masked,r_curve_left,r_curve_right,left_lane_fit_x,right_lane_fit_x,left_lane_fit,right_lane_fit,y_plot)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(final_out)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define line class and processing pipeline\n",
    "We define a line class that stores vital information as we process lane lines in a video. Our processing pipeline brings together all the functions and processing steps we outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # tracks lane curvature\n",
    "        self.recent_r_curve = []\n",
    "        # keeps track of initial x location when line was discovered\n",
    "        self.initial_loc = None\n",
    "        # recent polynomial coefficients\n",
    "        self.recent_fit = []\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        # x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        # y values for detected line pixels\n",
    "        self.ally = None\n",
    "        # counter to reset if issues persist after 5 iterations\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(img):\n",
    "    # retrieve image dimensions\n",
    "    height,width = img.shape[:2]\n",
    "    \n",
    "    # undistorted image\n",
    "    img_undistorted = undistort_image(img)\n",
    "    \n",
    "    # apply color and gradient threshold\n",
    "    binary_white,binary_yellow,binary_s,binary_x,binary_y,binary_mag,binary_dir=gradient_threshold_pipeline(img_undistorted,sobel_kernel=11,color_thresh=(15,50),mag_thresh=(25,255),dir_thresh=(0.65,1.25))\n",
    "    binary_combined1 = np.zeros_like(binary_x)\n",
    "    binary_combined1[((binary_x == 1) & (binary_y == 1)) | ((binary_mag == 1) & (binary_dir == 1))] = 1\n",
    "    binary_combined2 = np.zeros_like(binary_x)\n",
    "    binary_combined2[((binary_white == 255) & (binary_combined1 == 1)) | ((binary_yellow == 255) & (binary_combined1 == 1))] = 1\n",
    "    \n",
    "    # finalized image is a combination of yellow/white color threshold, and a mixture of x,y, magnitude, and direction gradient\n",
    "    final_image = np.dstack((binary_yellow,binary_white,binary_combined2*255))\n",
    "    final_image_gray = cv2.cvtColor(final_image,cv2.COLOR_RGB2GRAY)\n",
    "    final_image_binary = np.zeros_like(final_image_gray)\n",
    "    final_image_binary[final_image_gray > 0] = 1\n",
    "    \n",
    "    # apply perspective transform to binary image to get a birds eye view of road\n",
    "    final_image_warped,final_image_unwarped,M,M_inv = perspective_transform(final_image_binary)\n",
    "\n",
    "    # define mask points and apply mask\n",
    "    width_offset_top = 0.36\n",
    "    width_offset_bottom = 0.36\n",
    "    height_offset = 0\n",
    "    x1,y1 = width*width_offset_bottom,height\n",
    "    x2,y2 = width*width_offset_top,height*height_offset\n",
    "    x3,y3 = width*(1-width_offset_top),height*height_offset\n",
    "    x4,y4 = width*(1-width_offset_bottom),height\n",
    "    region = np.array([[(x1,y1),(x2,y2),(x3,y3),(x4,y4)]],dtype=np.int32)\n",
    "    final_image_warped_masked = region_mask(final_image_warped,region)\n",
    "    \n",
    "    # find the general region of where lanes are located on image\n",
    "    if left_line.detected == False | right_line.detected == False:\n",
    "        # print('first time detecting')\n",
    "        initial_left_lane_x, initial_right_lane_x = initial_lane_detection(final_image_warped_masked)\n",
    "        left_line.initial_x = initial_left_lane_x\n",
    "        right_line.initial_x = initial_right_lane_x\n",
    "        left_line.detected = True\n",
    "        right_line.detected = True\n",
    "        \n",
    "    img_out,left_lane_fit,right_lane_fit,left_lane_fit_x,right_lane_fit_x,left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list,y_plot = continuous_lane_detection(final_image_warped_masked,left_line.initial_x,right_line.initial_x)\n",
    "    \n",
    "    try:\n",
    "        n = 5\n",
    "        left_line.current_fit = left_lane_fit # finds best fit\n",
    "        left_line.all_x = left_lane_x_list\n",
    "        left_line.all_y = left_lane_y_list\n",
    "        left_line.recent_fit.append(left_line.current_fit)\n",
    "        if len(left_line.recent_fit) > 1:\n",
    "            left_line.diffs = (left_line.recent_fit[-2] - left_line.recent_fit[-1]) / left_line.recent_fit[-2]\n",
    "        left_line.recent_fit = left_line.recent_fit[-n:]\n",
    "        left_line.best_fit = np.mean(left_line.recent_fit, axis = 0)\n",
    "        left_fit = left_line.current_fit\n",
    "        left_line.detected = True\n",
    "        left_line.count = 0\n",
    "    except TypeError:\n",
    "        left_fit = left_line.best_fit\n",
    "        left_line.detected = False\n",
    "    except np.linalg.LinAlgError:\n",
    "        left_fit = left_line.best_fit\n",
    "        left_line.detected = False\n",
    "    \n",
    "    try:\n",
    "        n = 5\n",
    "        right_line.current_fit = right_lane_fit # finds best fit\n",
    "        right_line.all_x = right_lane_x_list\n",
    "        right_line.all_y = right_lane_y_list\n",
    "        right_line.recent_fit.append(right_line.current_fit)\n",
    "        if len(right_line.recent_fit) > 1:\n",
    "            right_line.diffs = (right_line.recent_fit[-2] - right_line.recent_fit[-1]) / right_line.recent_fit[-2]\n",
    "        right_line.recent_fit = right_line.recent_fit[-n:]\n",
    "        right_line.best_fit = np.mean(right_line.recent_fit, axis = 0)\n",
    "        right_fit = right_line.current_fit\n",
    "        right_line.detected = True\n",
    "        right_line.counter = 0\n",
    "    except TypeError:\n",
    "        right_fit = right_line.best_fit\n",
    "        right_line.detected = False\n",
    "    except np.linalg.LinAlgError:\n",
    "        right_fit = right_line.best_fit\n",
    "        right_line.detected = False\n",
    "    \n",
    "    # left/right curvature is calculated\n",
    "    r_curve_left,r_curve_right,left_lane_fit,right_lane_fit = curvature(left_lane_x_list,right_lane_x_list,left_lane_y_list,right_lane_y_list)\n",
    "\n",
    "    left_line.recent_r_curve.append(r_curve_left)\n",
    "    right_line.recent_r_curve.append(r_curve_right)\n",
    "\n",
    "    max_r_curve_data = 30\n",
    "    if len(left_line.recent_r_curve) > max_r_curve_data:\n",
    "        left_line.recent_r_curve = left_line.recent_r_curve[-max_r_curve_data:]\n",
    "        right_line.recent_r_curve = right_line.recent_r_curve[-max_r_curve_data:]\n",
    "    \n",
    "    if len(left_line.recent_r_curve) > 1:\n",
    "        weights = np.linspace(0,1,len(left_line.recent_r_curve))/(len(left_line.recent_r_curve)/2)\n",
    "        left_r_curve_avg = np.average(left_line.recent_r_curve,weights=weights)\n",
    "        right_r_curve_avg = np.average(right_line.recent_r_curve,weights=weights)\n",
    "    else:\n",
    "        left_r_curve_avg = np.average(left_line.recent_r_curve)\n",
    "        right_r_curve_avg = np.average(right_line.recent_r_curve)\n",
    "    \n",
    "    # plot lane mask and text\n",
    "    final_out = plot_lane_mask(img_undistorted,final_image_warped_masked,r_curve_left,r_curve_right,left_lane_fit_x,right_lane_fit_x,left_lane_fit,right_lane_fit,y_plot)\n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process test video using our pipeline\n",
    "Finally, we test our advanced lane finding pipeline by processing a sample video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "# Pipeline.set_values(line, M, Minv, cameraMat, distCoeffs)\n",
    "\n",
    "# import all chessboard camera calibration images using the glob package\n",
    "chess_image_paths = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# retrieve camera calibration values using our custom camera_calibration function\n",
    "chess_images, ret, mtx, dist, rvecs, tvecs = camera_calibration(chess_image_paths)\n",
    "\n",
    "output_video_title = 'project_video_out.mp4'\n",
    "clip1 = VideoFileClip('project_video.mp4')\n",
    "output_video = clip1.fl_image(main_pipeline)\n",
    "%time output_video.write_videofile(output_video_title, audio=False)\n",
    "\n",
    "# video_clip.reader.close()\n",
    "# video_clip.audio.reader.close_proc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "As we can see, our pipeline appears to handle lane lines quite well. (Note: Click on the image to watch the full video on youtube).\n",
    "\n",
    "<a href='https://www.youtube.com/watch?v=svgmZxfS5C8'>![Test](project_video_out.gif)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "1. The model performed just OK on the challenge video but poorly on the harder challenge due to vastly different lighting and road conditions. I'd like to revist them when time permits.\n",
    "2. I'd like to incorporate more redundancy checks in the model. For example, in the event that there's shadows in an image that disrupt the identification of the left lane line while the right lane line remains unaffected, I'd like the model to piggy-back on the right lane line when estimating the curvature of the left lane line.\n",
    "3. It might be interesting to see how well this model can perform on other roads and conditions. \n",
    "4. Developing a smoothing system that uses recent historical lane line data would further enhance the models ability to detect lane lines and mitigate the outliers that may arise in some road conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
